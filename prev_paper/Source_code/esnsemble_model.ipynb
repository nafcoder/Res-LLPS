{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1066308",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pathlib\n",
    "import torch\n",
    "import esm\n",
    "from esm import pretrained\n",
    "from esm import FastaBatchedDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc81218a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-26 21:22:57.767346: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-26 21:22:57.871931: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1769440977.914515    6709 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1769440977.926495    6709 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1769440978.016302    6709 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769440978.016330    6709 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769440978.016331    6709 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769440978.016332    6709 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2026-01-26 21:22:58.027296: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/nafiislam/anaconda3/envs/py39/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "W0000 00:00:1769440988.420552    6709 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Accuracy: 0.774\n",
      "Sensitivity: 0.743\n",
      "Specificity: 0.793\n",
      "Precision: 0.689\n",
      "F1 Score: 0.715\n",
      "MCC: 0.530\n",
      "AUC: 0.831\n",
      "auPR: 0.731\n",
      "Balanced Accuracy: 0.768\n"
     ]
    }
   ],
   "source": [
    "import re, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import torch\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# sort filenames in order\n",
    "def numeric_sort(file_list):\n",
    "    def extract_num(f):\n",
    "        m = re.search(r'(\\d+)', f)\n",
    "        return int(m.group(1)) if m else float('inf')\n",
    "    return sorted(file_list, key=extract_num)\n",
    "\n",
    "# Load the query sequence representations\n",
    "def load_protein_representations(folder_path, files):\n",
    "    queryproteinrep = []\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.exists(file_path):\n",
    "            rep_changes = torch.load(file_path)['mean_representations'][36]\n",
    "            queryproteinrep.append(rep_changes.tolist())\n",
    "        else:\n",
    "            print(f\"File {file_path} not found.\")\n",
    "    return torch.tensor(queryproteinrep)\n",
    "\n",
    "\n",
    "# Automatically detect project root\n",
    "current_path = pathlib.Path().resolve()\n",
    "\n",
    "current_path = current_path.parent\n",
    "\n",
    "project_root = current_path\n",
    "\n",
    "# Path to sequence representations\n",
    "folder_path = project_root / \"embeddings\"\n",
    "files_test = os.listdir(folder_path)\n",
    "files_test = numeric_sort(files_test)  # Sort files numerically\n",
    "\n",
    "pos = pd.read_csv(\"/media/nafiislam/T7/LLPSEmbed_new/averaged_features/ESM2_3B/embeddings_test_positive.csv\", header=None).values\n",
    "neg = pd.read_csv(\"/media/nafiislam/T7/LLPSEmbed_new/averaged_features/ESM2_3B/embeddings_test_negative.csv\", header=None).values\n",
    "query_rep = np.vstack((pos, neg))\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(2560,)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')  \n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "# Load all saved models for ensemble predictions\n",
    "import glob\n",
    "\n",
    "# Path to models directory using project_root\n",
    "models_path = project_root / \"models\"\n",
    "model_files = sorted(models_path.glob(\"dataset_*.h5\"))\n",
    "\n",
    "# Convert Path objects to strings for compatibility if needed\n",
    "#model_files = [str(file) for file in model_files]\n",
    "\n",
    "# Initialize lists for ensemble predictions\n",
    "loaded_predictions = []\n",
    "loaded_probabilities = []\n",
    "\n",
    "\n",
    "for model_file in model_files:\n",
    "    loaded_model = load_model(model_file, compile = False)\n",
    "    # Make predictions on the test set\n",
    "    y_pred_proba = loaded_model.predict(query_rep, verbose=0)\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "    loaded_predictions.append(y_pred)\n",
    "    loaded_probabilities.append(y_pred_proba)\n",
    "    \n",
    "# Convert predictions and probabilities to numpy arrays\n",
    "ensemble_predictions = np.array(loaded_predictions)  \n",
    "ensemble_probabilities = np.array(loaded_probabilities) \n",
    "\n",
    "# Using the model to make predictions\n",
    "predictions = model.predict(query_rep)\n",
    "predicted_labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "# After all folds are processed, calculate the final ensemble accuracy and other metrics\n",
    "ensemble_predictions = np.array(ensemble_predictions)  \n",
    "ensemble_probabilities = np.array(ensemble_probabilities) \n",
    "\n",
    "# Majority voting for final predictions\n",
    "votes = np.sum(ensemble_predictions, axis=0)  \n",
    "majority_decision = (votes > (ensemble_predictions.shape[0] // 2)).astype(int)\n",
    "\n",
    "# Handle ties (if any)\n",
    "ties = (votes == ensemble_predictions.shape[0] // 2)  \n",
    "if np.any(ties):\n",
    "    avg_probabilities = ensemble_probabilities.mean(axis=0)\n",
    "    majority_decision[ties] = (avg_probabilities[ties] >= 0.5).astype(int)\n",
    "\n",
    "# Final ensemble predictions\n",
    "final_predictions = majority_decision\n",
    "final_probabilities = ensemble_probabilities.mean(axis=0)\n",
    "\n",
    "y_true = np.array([1]*len(pos) + [0]*len(neg))\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score, confusion_matrix, matthews_corrcoef,\n",
    ")\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "\n",
    "def find_metrics(y_test, y_predict, y_proba):\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()  # y_true, y_pred\n",
    "\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_predict)\n",
    "    prec = tp / (tp + fp)\n",
    "    f1_score_1 = 2 * prec * sensitivity / (prec + sensitivity)\n",
    "    mcc = matthews_corrcoef(y_test, y_predict)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    auPR = average_precision_score(y_test, y_proba)\n",
    "    bal_acc = balanced_accuracy_score(y_test, y_predict)\n",
    "\n",
    "    return sensitivity, specificity, acc, prec, f1_score_1, mcc, auc, y_proba, bal_acc, auPR\n",
    "\n",
    "sensitivity, specificity, acc, prec, f1_score_1, mcc, auc, y_proba, bal_acc, auPR = find_metrics(y_true, final_predictions, final_probabilities)\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "print(f\"Sensitivity: {sensitivity:.3f}\")\n",
    "print(f\"Specificity: {specificity:.3f}\")\n",
    "print(f\"Precision: {prec:.3f}\")\n",
    "print(f\"F1 Score: {f1_score_1:.3f}\")\n",
    "print(f\"MCC: {mcc:.3f}\")\n",
    "print(f\"AUC: {auc:.3f}\")\n",
    "print(f\"auPR: {auPR:.3f}\")\n",
    "print(f\"Balanced Accuracy: {bal_acc:.3f}\")\n",
    "\n",
    "np.save(\"y_proba.npy\", final_probabilities)\n",
    "np.save(\"y_true.npy\", y_true)\n",
    "np.save(\"y_predict.npy\", final_predictions)\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import csv\n",
    "\n",
    "fpr, tpr, _ = roc_curve(np.array(y_true), np.array(final_probabilities))\n",
    "\n",
    "f = open(\"./outputs_ensemble/fpr.csv\", \"w\", newline=\"\")\n",
    "writer = csv.writer(f)\n",
    "writer.writerows([[fp] for fp in fpr])\n",
    "f.close()\n",
    "\n",
    "f = open(\"./outputs_ensemble/tpr.csv\", \"w\", newline=\"\")\n",
    "writer = csv.writer(f)\n",
    "writer.writerows([[tp] for tp in tpr])\n",
    "f.close()\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(np.array(y_true), np.array(final_probabilities))\n",
    "\n",
    "f_name = f'./outputs_ensemble/precision.csv'\n",
    "with open(f_name, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows([[p] for p in precision])\n",
    "\n",
    "f_name = f'./outputs_ensemble/recall.csv'\n",
    "with open(f_name, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows([[r] for r in recall])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
